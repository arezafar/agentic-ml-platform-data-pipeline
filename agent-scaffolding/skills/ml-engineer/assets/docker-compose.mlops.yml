# =============================================================================
# Agentic MLOps Infrastructure - Docker Compose
# =============================================================================
#
# Multi-service stack for ML Engineer JTBD workflow:
# - Mage: The Orchestrator (Control Plane)
# - H2O: The Compute Engine (Muscle)
# - PostgreSQL: The State Manager (Memory)
# - Serving: The Production Endpoint (Value Delivery)
#
# Usage:
#   docker-compose -f docker-compose.mlops.yml up -d
#   Open http://localhost:6789 for Mage UI
#   Open http://localhost:54321 for H2O Flow UI
#
# =============================================================================

version: '3.8'

services:
  # ---------------------------------------------------------------------------
  # The Orchestrator - Mage
  # The "Brain" - Controls pipeline logic, triggers, and agent workflow
  # ---------------------------------------------------------------------------
  mage-ai:
    image: mageai/mageai:latest
    container_name: mlops-mage
    hostname: mage
    command: mage start mlops_project
    ports:
      - "6789:6789"
    environment:
      PROJECT_NAME: mlops_project
      # Database connection for pipeline state
      MAGE_DATABASE_CONNECTION_URL: postgresql://${POSTGRES_USER:-mage}:${POSTGRES_PASSWORD:-mage_secret}@postgres:5432/${POSTGRES_DB:-mage_db}
      # H2O cluster URL for tool use
      H2O_URL: http://h2o-ai:54321
      # Shared data path for zero-copy transfer
      DATA_EXCHANGE_PATH: /data/exchange
      # Global variables for JTBD workflow
      PRIMARY_METRIC: ${PRIMARY_METRIC:-AUC}
      MAX_RUNTIME_SECS: ${MAX_RUNTIME_SECS:-3600}
    volumes:
      # Pipeline code persistence
      - ./mage_pipeline:/home/src/mlops_project
      # CRITICAL: Shared volume for zero-copy data transfer
      - shared_data:/data
      # MOJO output path
      - model_artifacts:/models
    depends_on:
      postgres:
        condition: service_healthy
      h2o-ai:
        condition: service_healthy
    networks:
      - ml-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6789/api/status"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 60s
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G

  # ---------------------------------------------------------------------------
  # The Compute Engine - H2O
  # The "Muscle" - Distributed ML training and inference
  # ---------------------------------------------------------------------------
  h2o-ai:
    image: h2oai/h2o-open-source-k8s:latest
    container_name: mlops-h2o
    hostname: h2o-ai
    ports:
      - "54321:54321"  # REST API
      - "54322:54322"  # Inter-node communication
    environment:
      # JVM memory configuration (critical for large datasets)
      JAVA_OPTS: -Xmx${H2O_XMX:-8g} -Xms${H2O_XMS:-4g}
    volumes:
      # Shared data for zero-copy import
      - shared_data:/data
      # Model output
      - model_artifacts:/models
    networks:
      - ml-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:54321/3/About"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 45s
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 10G
        reservations:
          cpus: '2'
          memory: 8G

  # ---------------------------------------------------------------------------
  # The State Manager - PostgreSQL
  # The "Memory" - Pipeline run history and metadata
  # ---------------------------------------------------------------------------
  postgres:
    image: postgres:15
    container_name: mlops-postgres
    hostname: postgres
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-mage}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-mage_secret}
      POSTGRES_DB: ${POSTGRES_DB:-mage_db}
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks:
      - ml-network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-mage}"]
      interval: 10s
      timeout: 5s
      retries: 5

  # ---------------------------------------------------------------------------
  # The Production Endpoint - Model Serving
  # The "Value Delivery" - Low-latency REST API for predictions
  # ---------------------------------------------------------------------------
  model-serving:
    build:
      context: ./serving
      dockerfile: Dockerfile
    container_name: mlops-serving
    hostname: serving
    ports:
      - "8080:8080"
    environment:
      MODEL_PATH: /models/production/model.mojo
      GENMODEL_JAR: /models/production/h2o-genmodel.jar
    volumes:
      - model_artifacts:/models:ro
    networks:
      - ml-network
    depends_on:
      - mage-ai
    profiles:
      - production
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G

networks:
  ml-network:
    driver: bridge
    name: mlops-network

volumes:
  # PostgreSQL data persistence
  pgdata:
    driver: local
  
  # Shared data exchange (zero-copy between Mage and H2O)
  shared_data:
    driver: local
  
  # Model artifacts (MOJOs, genmodel jars)
  model_artifacts:
    driver: local
