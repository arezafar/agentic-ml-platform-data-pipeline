#!/usr/bin/env python3
"""
Agentic DDL Generator

Extends the base DDL generator with support for:
- pgvector extension and VECTOR columns
- HNSW/IVFFlat index creation
- Hybrid search query templates
- Semantic search function generation

Usage:
    python generate_agentic_ddl.py --schema agentic_schema_template.json --output output.sql
    python generate_agentic_ddl.py --schema agentic_schema_template.json --format sql
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Any, Optional


class AgenticDDLGenerator:
    """Generate PostgreSQL DDL for agentic memory schemas with pgvector."""
    
    # Type mapping for agentic-specific types
    TYPE_MAP = {
        'uuid': 'UUID',
        'text': 'TEXT',
        'varchar': 'VARCHAR',
        'integer': 'INTEGER',
        'int': 'INTEGER',
        'bigint': 'BIGINT',
        'float': 'FLOAT',
        'double': 'DOUBLE PRECISION',
        'boolean': 'BOOLEAN',
        'bool': 'BOOLEAN',
        'timestamptz': 'TIMESTAMPTZ',
        'timestamp': 'TIMESTAMP',
        'date': 'DATE',
        'jsonb': 'JSONB',
        'json': 'JSON',
        'inet': 'INET',
    }
    
    def __init__(self, schema_data: dict):
        self.schema = schema_data
        self.ddl_statements: list[str] = []
        self.indexes: list[str] = []
        self.functions: list[str] = []
    
    def generate(self) -> str:
        """Generate complete DDL output."""
        self._generate_header()
        self._generate_extensions()
        self._generate_schemas()
        self._generate_tables()
        self._generate_indexes()
        self._generate_functions()
        self._generate_seed_data()
        
        return '\n\n'.join(self.ddl_statements)
    
    def _generate_header(self) -> None:
        """Generate DDL header with metadata."""
        schema_name = self.schema.get('name', 'unknown')
        version = self.schema.get('version', '1.0.0')
        description = self.schema.get('description', '')
        
        self.ddl_statements.append(f"""-- =============================================================================
-- Auto-generated DDL: {schema_name} v{version}
-- Description: {description}
-- Generated by: Agentic DDL Generator
-- =============================================================================
""")
    
    def _generate_extensions(self) -> None:
        """Generate CREATE EXTENSION statements."""
        extensions = self.schema.get('extensions', [])
        if not extensions:
            return
        
        ext_stmts = ['-- Extensions']
        for ext in extensions:
            name = ext.get('name', '')
            desc = ext.get('description', '')
            ext_stmts.append(f"CREATE EXTENSION IF NOT EXISTS {name};  -- {desc}")
        
        self.ddl_statements.append('\n'.join(ext_stmts))
    
    def _generate_schemas(self) -> None:
        """Generate CREATE SCHEMA statements."""
        schemas = self.schema.get('schemas', [])
        if not schemas:
            return
        
        schema_stmts = ['-- Schemas']
        for s in schemas:
            name = s.get('name', '')
            desc = s.get('description', '')
            schema_stmts.append(f"CREATE SCHEMA IF NOT EXISTS {name};")
            if desc:
                schema_stmts.append(f"COMMENT ON SCHEMA {name} IS '{desc}';")
        
        self.ddl_statements.append('\n'.join(schema_stmts))
    
    def _generate_tables(self) -> None:
        """Generate CREATE TABLE statements."""
        tables = self.schema.get('tables', {})
        
        for table_name, table_def in tables.items():
            self._generate_table(table_name, table_def)
    
    def _generate_table(self, table_name: str, table_def: dict) -> None:
        """Generate DDL for a single table."""
        columns = table_def.get('columns', {})
        description = table_def.get('description', '')
        
        col_defs = []
        pk_cols = []
        fk_constraints = []
        check_constraints = []
        
        for col_name, col_def in columns.items():
            col_sql = self._generate_column(col_name, col_def)
            col_defs.append(col_sql)
            
            if col_def.get('primary_key'):
                pk_cols.append(col_name)
            
            if 'foreign_key' in col_def:
                fk = col_def['foreign_key']
                fk_constraints.append(
                    f"    FOREIGN KEY ({col_name}) REFERENCES {fk['references']}({fk['column']})"
                    f"{' ON DELETE ' + fk.get('on_delete', 'NO ACTION') if 'on_delete' in fk else ''}"
                )
            
            if 'check' in col_def:
                check_constraints.append(
                    f"    CHECK ({col_def['check']})"
                )
        
        # Build CREATE TABLE statement
        table_sql = [f"CREATE TABLE IF NOT EXISTS {table_name} ("]
        table_sql.append(',\n'.join(col_defs))
        
        if fk_constraints:
            table_sql.append(',\n' + ',\n'.join(fk_constraints))
        
        table_sql.append('\n);')
        
        full_sql = ''.join(table_sql)
        
        if description:
            full_sql += f"\n\nCOMMENT ON TABLE {table_name} IS '{description}';"
        
        self.ddl_statements.append(full_sql)
        
        # Store indexes for later generation
        for idx in table_def.get('indexes', []):
            self.indexes.append((table_name, idx))
    
    def _generate_column(self, col_name: str, col_def: dict) -> str:
        """Generate column definition."""
        col_type = col_def.get('type', 'TEXT')
        
        # Handle vector type specially
        if col_type.startswith('vector'):
            pg_type = col_type.upper()
        elif '(' in col_type:
            # Type with parameters like varchar(100)
            base_type = col_type.split('(')[0]
            params = col_type.split('(')[1]
            pg_type = f"{self.TYPE_MAP.get(base_type, base_type.upper())}({params}"
        else:
            pg_type = self.TYPE_MAP.get(col_type, col_type.upper())
        
        parts = [f"    {col_name} {pg_type}"]
        
        if col_def.get('primary_key'):
            parts.append("PRIMARY KEY")
        
        if col_def.get('nullable') == False or col_def.get('nullable') is False:
            parts.append("NOT NULL")
        
        if 'default' in col_def:
            parts.append(f"DEFAULT {col_def['default']}")
        
        if 'check' in col_def:
            parts.append(f"CHECK ({col_def['check']})")
        
        return ' '.join(parts)
    
    def _generate_indexes(self) -> None:
        """Generate CREATE INDEX statements."""
        if not self.indexes:
            return
        
        idx_stmts = ['-- Indexes']
        
        for table_name, idx_def in self.indexes:
            idx_name = idx_def.get('name', f"idx_{table_name.replace('.', '_')}")
            idx_type = idx_def.get('type', 'btree').upper()
            columns = idx_def.get('columns', [])
            
            if idx_type == 'HNSW':
                # Vector index with special syntax
                op_class = idx_def.get('operator_class', 'vector_cosine_ops')
                params = idx_def.get('parameters', {})
                param_str = ', '.join([f"{k} = {v}" for k, v in params.items()])
                
                idx_sql = (
                    f"CREATE INDEX IF NOT EXISTS {idx_name}\n"
                    f"    ON {table_name}\n"
                    f"    USING hnsw ({', '.join(columns)} {op_class})"
                )
                if param_str:
                    idx_sql += f"\n    WITH ({param_str})"
                idx_sql += ";"
                
            elif idx_type == 'GIN':
                idx_sql = (
                    f"CREATE INDEX IF NOT EXISTS {idx_name}\n"
                    f"    ON {table_name}\n"
                    f"    USING gin ({', '.join(columns)});"
                )
                
            else:
                # Standard B-tree index
                where_clause = idx_def.get('where', '')
                order = idx_def.get('order', 'ASC')
                
                cols_with_order = [f"{c} {order}" if order != 'ASC' else c for c in columns]
                
                idx_sql = (
                    f"CREATE INDEX IF NOT EXISTS {idx_name}\n"
                    f"    ON {table_name} ({', '.join(cols_with_order)})"
                )
                if where_clause:
                    idx_sql += f"\n    WHERE {where_clause}"
                idx_sql += ";"
            
            idx_stmts.append(idx_sql)
        
        self.ddl_statements.append('\n\n'.join(idx_stmts))
    
    def _generate_functions(self) -> None:
        """Generate helper functions for agentic operations."""
        functions = """
-- =============================================================================
-- Helper Functions
-- =============================================================================

-- Function: Check if system is halted (kill-switch)
CREATE OR REPLACE FUNCTION system_control.is_halted() 
RETURNS BOOLEAN AS $$
DECLARE
    halt_status BOOLEAN;
BEGIN
    SELECT (setting_value->>'enabled')::boolean INTO halt_status
    FROM system_control.global_settings
    WHERE setting_key = 'global_halt';
    
    RETURN COALESCE(halt_status, FALSE);
END;
$$ LANGUAGE plpgsql STABLE;

-- Function: Semantic search in knowledge base
CREATE OR REPLACE FUNCTION agent_memory.semantic_search(
    query_embedding VECTOR(1536),
    limit_count INTEGER DEFAULT 10,
    source_filter VARCHAR DEFAULT NULL
)
RETURNS TABLE(
    item_id UUID,
    content_chunk TEXT,
    source_type VARCHAR,
    similarity FLOAT
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        ki.item_id,
        ki.content_chunk,
        ki.source_type,
        1 - (ki.embedding <=> query_embedding) AS similarity
    FROM agent_memory.knowledge_items ki
    WHERE 
        (source_filter IS NULL OR ki.source_type = source_filter)
        AND ki.embedding IS NOT NULL
    ORDER BY ki.embedding <=> query_embedding
    LIMIT limit_count;
END;
$$ LANGUAGE plpgsql STABLE;

-- Function: Get recent episodes for a session
CREATE OR REPLACE FUNCTION agent_memory.get_session_context(
    p_session_id UUID,
    limit_count INTEGER DEFAULT 20
)
RETURNS TABLE(
    actor_role VARCHAR,
    message_content TEXT,
    tool_call_details JSONB,
    sequence_number INTEGER
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        e.actor_role,
        e.message_content,
        e.tool_call_details,
        e.sequence_number
    FROM agent_memory.episodes e
    WHERE e.session_id = p_session_id
    ORDER BY e.sequence_number DESC
    LIMIT limit_count;
END;
$$ LANGUAGE plpgsql STABLE;

-- Function: Register a new model in the registry
CREATE OR REPLACE FUNCTION h2o_intelligence.register_model(
    p_model_id VARCHAR,
    p_model_name VARCHAR,
    p_algorithm VARCHAR,
    p_problem_type VARCHAR,
    p_capabilities TEXT,
    p_required_features JSONB,
    p_mojo_path TEXT DEFAULT NULL
)
RETURNS VARCHAR AS $$
BEGIN
    INSERT INTO h2o_intelligence.model_registry (
        model_id, model_name, algorithm, problem_type,
        capabilities_description, required_features, mojo_path
    ) VALUES (
        p_model_id, p_model_name, p_algorithm, p_problem_type,
        p_capabilities, p_required_features, p_mojo_path
    )
    ON CONFLICT (model_id) DO UPDATE SET
        model_name = EXCLUDED.model_name,
        algorithm = EXCLUDED.algorithm,
        capabilities_description = EXCLUDED.capabilities_description,
        mojo_path = EXCLUDED.mojo_path;
    
    RETURN p_model_id;
END;
$$ LANGUAGE plpgsql;
"""
        self.ddl_statements.append(functions)
    
    def _generate_seed_data(self) -> None:
        """Generate INSERT statements for seed data."""
        tables = self.schema.get('tables', {})
        seed_stmts = ['-- Seed Data']
        has_seed = False
        
        for table_name, table_def in tables.items():
            seed_data = table_def.get('seed_data', [])
            if not seed_data:
                continue
            
            has_seed = True
            for row in seed_data:
                cols = ', '.join(row.keys())
                vals = []
                for v in row.values():
                    if isinstance(v, dict):
                        vals.append(f"'{json.dumps(v)}'::jsonb")
                    elif isinstance(v, str):
                        vals.append(f"'{v}'")
                    elif v is None:
                        vals.append('NULL')
                    else:
                        vals.append(str(v))
                
                seed_stmts.append(
                    f"INSERT INTO {table_name} ({cols})\n"
                    f"VALUES ({', '.join(vals)})\n"
                    f"ON CONFLICT DO NOTHING;"
                )
        
        if has_seed:
            self.ddl_statements.append('\n\n'.join(seed_stmts))


def main():
    parser = argparse.ArgumentParser(description='Generate PostgreSQL DDL for agentic schemas')
    parser.add_argument('--schema', '-s', required=True, help='JSON schema file')
    parser.add_argument('--output', '-o', help='Output SQL file (stdout if not specified)')
    parser.add_argument('--format', choices=['sql', 'json'], default='sql')
    
    args = parser.parse_args()
    
    schema_path = Path(args.schema)
    if not schema_path.exists():
        print(f"Error: Schema file not found: {schema_path}", file=sys.stderr)
        sys.exit(1)
    
    with open(schema_path) as f:
        schema_data = json.load(f)
    
    generator = AgenticDDLGenerator(schema_data)
    ddl = generator.generate()
    
    if args.output:
        with open(args.output, 'w') as f:
            f.write(ddl)
        print(f"DDL written to: {args.output}")
    else:
        print(ddl)


if __name__ == '__main__':
    main()
